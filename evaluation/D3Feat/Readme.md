github:https://github.com/XuyangBai/D3Feat
1. ply_eval folder to D3Feat main folder
  * https://www.microsoft.com/en-us/research/project/rgb-d-dataset-7-scenes/
  * demo files ply_eval/color_eval and ply_eval/depth_eval manually selected depth, color for generating ply, corresponding to pairs.txt
  * You can copy PointDSC-master/ply_eval/color_eval and depth_eval to D3Feat/ply_eval
  * The point cloud file for the test can be generated with /Hypothesis/registration_evaluate/generate_pointcloud.py
  * fx, fy, cx, cy =585,585,320,240
2. demo_3dmatch_registration.py into D3Feat main folder
  * modify logfile path to save all 4*4 matrices generated by "d3feat"
  * pairs.txt specifies the source and target point clouds, the former is the target point cloud, the latter is the source point cloud (pairs are named by the rgb corresponding to ply)
3. Run demo_3dmatch_registration.py
  * Can control whether to visualize after each generated rt
  * The rt matrix generated by each group of point clouds is saved in the log file