# Global Strongly Constrained Voting Mechanism for RGB-D Point Cloud Registration
Pytorch implementation of GSC-VM for paper "Global Strongly Constrained Voting Mechanism for RGB-D Point Cloud Registration"
This paper focus on outlier rejection for 3D point clouds registration. 
![fig1](figures/Fig1.png)
## Introduction
Point cloud registration is a crucial task in robotics, computer vision, and 3D reconstruction. Existing methods for outlier removal in RGB-D point cloud registration often rely on distance or angle metrics or deep learning techniques, which may not adequately address challenges related to geometric angles, distances, and global constraints. In this paper, we present the Global Strongly Constrained Voting Mechanism (GSC-VM), a novel outlier removal approach for RGB-D point cloud registration that outperforms traditional metrics and deep learning methods. GSC-VM utilizes a voting mechanism to gain confidence in registered feature point pairs, emphasizing its benefits in terms of geometric angles, distances, and global constraints. The method filters out point pairs that do not meet the constraint conditions, significantly reducing the possibility of mismatching point pairs. GSC-VM establishes pixel-wise dense feature matches at a coarse level using SuperGlue in RGB images and votes in 3D space based on metric distance and angle to obtain good point pairs matching at a fine level. Our comprehensive experiments on the 3DMatch and 3DLowMatch datasets demonstrate that GSC-VM significantly outperforms state-of-the-art methods in RGB-D point cloud registration, making it a valuable contribution to the field. 
Step1. The key alignment feature pairs are extracted from the source and target color maps with superglue to get the coarse alignment of key point matching.
Step2. The key points obtained from step1 are converted from the pixel coordinate system to the camera coordinate system by using the depth camera parameter to get the key alignment feature pairs corresponding in the 3D point cloud, and then the alignment information of the feature points is voted by the distance and angle through the metric model to get the fine alignment of good point matching.
Step3.To use the good point matching fine alignment obtained from step2 for point cloud registration
Our proposed GSC-VM also works best in industrial applications of 3D Reconstruction.

## Installation
See requirements.txt. 
code has been tested with Ubuntu 20.04,GCC 7.5.0，python 3.8.0,PyTorch 1.7.1+cu110，CUDA11.0.

Pre-trained Weights
We provide pre-trained weights superglue_indoor.pth in the SPVoteNet folder.

The code is heavily borrowed from [SuperGlue](https://github.com/magicleap/SuperGluePretrainedNetwork) 
## DATASET
The dataset can be downloaded from https://3dmatch.cs.princeton.edu/ .
You can use your dataset as TUM format. We also provide a simple example of TUM format.
The demo data are provided by [BaiDuPan](https://pan.baidu.com/s/1M97myAn5iYDa1V49FJU2xA)  Extraction Code: 1234

## Demo
We provide a small demo to register them using SPVoteNet. The data files are saved in the demo_data folder, which can be replaced by your own data. 
1. two-view 3D point cloud reconstruction by SPVoteNet.
    1.1 When testing the 3DMATCH dataset (point cloud files are needed, automatic point cloud file generation requires changes to the program).
        1.1.1 overall test: first put the 3DMATCH dataset into the tum-data folder, put the document ply_to_png into the living_room_png folder.
            modify the path, etc., run main_living_all.py for registration.
        1.1.2 Two point clouds registration: the same as above to place the data set, etc., modify, run main_living_one.py
    Note: the txt generated by superglue is stored in the textliving folder, which can be modified by match2WZH_living.py
    1.2 Test tum dataset, no point cloud file, need rgb image and depth image, first put adjust.py into rgb folder, run to generate remove none depth points
        1.2.1 Overall test: modify the correspondence, and run main_tums.py
        1.2.2 Two point clouds test: same as above, run main_tums_one.py
        Note: the txt generated by superglue is stored in the textliving folder, which can be modified by match2WZH_TEST.py
        The images are stored in imgtest, the txt in txttest
2. splice livingroom dataset by icp: splice all point clouds: icp.py, splice two point clouds: icp_one.py
notes:
Hypothesis.py performs fine alignment of all 20 pairs of points in the test folder that have been coarsely aligned with superGlue.
FilterNet.py to train the neural network 
pcd.py Generate point clouds using rgb and depth maps
If Voting result is: {0: 1, 1: 1, 2: 1, 3: -1, 4: -1, 5: -1, 6: -1, 7: -1, 8: -1, 9: -1}, then the index of the number of votes from smallest to largest is: [3, 4, 5, 6, 7, 8, 9, 0, 1, 2]
If you will to evaluate D3Feat,please install the [D3Feat](https://github.com/XuyangBai/D3Feat), and see evaluation/D3Feat/readme.md.
If you will to evaluate PointDSC,please install the [PointDSC](https://github.com/XuyangBai/PointDSC), and see evaluation/PointDSC/readme.md .
If you will to evaluate GeoTransformer,please install the [GeoTransformer](https://github.com/qinzheng93/GeoTransformer),and see evaluation/GeoTransformer/readme.md.
If you will to evaluate ICP,please see Hypothesis.py
## References
<a name="refs"></a>
[1] 3DMatch: Learning Local Geometric Descriptors from RGB-D Reconstructions, Andy Zeng, Shuran Song, Matthias Nießner, Matthew Fisher, Jianxiong Xiao, and Thomas Funkhouser, CVPR 2017.

[2] Superglue: Learning feature matching with graph neural networks, in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 2020.

[3] Beyond self-attention: External attention using two linear layers for visual tasks, IEEE Transactions on Pattern Analysis and Machine Intelligence, 2022.
